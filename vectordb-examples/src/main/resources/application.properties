server.port=8000

#spring.ai.ollama.base-url=localhost:11434
#Default url is localhost:11434. So no need to set.

#spring.ai.ollama.embedding.enabled=true\
#It is enabled by default.

#spring.ai.ollama.embedding.options.model=llama3
#Commented because we cannot use LLM in ING
#Default model is mistral. But we are running llama2. So changed here.

spring.datasource.password=postgres
spring.datasource.username=postgres
spring.datasource.url=jdbc:postgresql://localhost/vector_store

#spring.ai.vectorstore.pgvector.index-type=HNSW
spring.ai.vectorstore.pgvector.index-type=NONE
#Indexing is disabled because the llama2 embedding model produces embeddings with dimension 4096 and pgvector cannot index vectors with more than 2000 dimensions.


#For allowing to upload large image fles to search
spring.servlet.multipart.max-file-size=100MB
spring.servlet.multipart.max-request-size=100MB
server.tomcat.max-swallow-size=100MB
